{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Biometrics_AutoEncoder_Run.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Biometrics-UT/AutoEncoderModelsPaper/blob/main/Biometrics_AutoEncoder_Run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2ba9sUNJcHJ"
      },
      "source": [
        "\n",
        "# Load the different libraries etc. \n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Import the needed things. \n",
        "from __future__ import print_function\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from keras.datasets import mnist\n",
        "from keras.datasets import cifar100\n",
        "from random import sample,randint\n",
        "from keras.layers import Input, Cropping2D\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import tqdm.notebook as tq\n",
        "import random\n",
        "from numpy import savetxt\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "from numpy import loadtxt\n",
        "from google.colab import files\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "# Set variabls\n",
        "# initialize the number of epochs and batch size\n",
        "EPOCHS = 50\n",
        "BS = 28\n",
        "\n",
        "# Set some initial parameters. \n",
        "batch_size = 100\n",
        "\n",
        "# Set image sizes\n",
        "img_sizeX = 500\n",
        "img_sizeY = 600\n",
        "input_shape=(img_sizeY,img_sizeX,3)\n",
        "input_img = Input(shape = input_shape)\n",
        "\n",
        "# Set bools\n",
        "sobel = False\n",
        "laplacian = True\n",
        "\n",
        "deep = True\n",
        "\n",
        "# Set the paths and filenames needed. \n",
        "main_path = \"/content/fgrc_dataset_train\"\n",
        "laplacian_one_path ='/content/LaplacianImages/Laplacian_1/'\n",
        "laplacian_two_path ='/content/LaplacianImages/Laplacian_2/'\n",
        "laplacian_three_path ='/content/LaplacianImages/Laplacian_3/'\n",
        "sobel_one_path ='/content/SobelImages/Sobel_1/'\n",
        "sobel_two_path ='/content/SobelImages/Sobel_2/'\n",
        "autoEncoderName = \"DeepLaplacianFilterFaces\"\n",
        "baseEpochs = 50\n",
        "loadNameFitting = None\n",
        "loadNamePrediction = None"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve7pDXsssref"
      },
      "source": [
        "#Mount the drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee5R8wDiFL_7"
      },
      "source": [
        "# The mean squared error. maybe remove. \n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true - y_pred)\n",
        "    return tf.reduce_mean(squared_difference, axis=-1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErgtGzFTWhlx"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IphVHaMpGhD"
      },
      "source": [
        "# Method to get Image given teh path and index\r\n",
        "def getImage(path,index,all_imagesNames):\r\n",
        "  # Get one test image for the \r\n",
        "  path = os.path.join(path, all_imagesNames[index])\r\n",
        "\r\n",
        "  img = cv2.imread(path)\r\n",
        "  RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "  rescaled = cv2.resize(RGB_img, (img_sizeX, img_sizeY))\r\n",
        "  rescaled = rescaled.astype('float32') / 255\r\n",
        "  return rescaled\r\n",
        "\r\n",
        "# Method that gets the numpy data. \r\n",
        "def getNpy(path, index, all_imagesNames):    \r\n",
        "    # load array\r\n",
        "    name = all_imagesNames[index]\r\n",
        "    imageName = name.split('.')[0]\r\n",
        "    path = os.path.join(path, imageName )\r\n",
        "    data = np.load(path + \".npy\")\r\n",
        "    return data\r\n",
        "\r\n",
        "# Methot that gets all the image names. \r\n",
        "def loadAllImageNames():\r\n",
        "\r\n",
        "  # Get all the image names. \r\n",
        "  all_imagesNames = []\r\n",
        "  for i in tq.tqdm(os.listdir(main_path)):\r\n",
        "      all_imagesNames.append(i)\r\n",
        "\r\n",
        "  # Shuffle the list for better results.\r\n",
        "  random.shuffle(all_imagesNames)\r\n",
        "\r\n",
        "  # Return the image names.\r\n",
        "  return all_imagesNames\r\n",
        "\r\n",
        "# Get a test image.\r\n",
        "def getTestImage(imageNames):\r\n",
        "  # Get one test image for the laplacian layers.  \r\n",
        "  kernelTestImage = []\r\n",
        "\r\n",
        "  # Get the image.\r\n",
        "  image = getImage(main_path,0,imageNames)\r\n",
        "\r\n",
        "  # Append it to the list.\r\n",
        "  kernelTestImage.append(np.array(image))\r\n",
        "\r\n",
        "  # Make it a workable numpy array.\r\n",
        "  kernelTestImage = np.reshape(kernelTestImage, (len(kernelTestImage), img_sizeY, img_sizeX, 3))\r\n",
        "\r\n",
        "  # Return the test image\r\n",
        "  return kernelTestImage"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5EkXd0nsGaZ"
      },
      "source": [
        "# The different kernels that can be called.\r\n",
        "def laplacian_kernel_one(shape, dtype=None):\r\n",
        "    \r\n",
        "    # Set the kernel.\r\n",
        "    kernel = [[ 0.000005074932907,  0.000176841611374,  0.001371042851508, 0.00265121170289 ,  0.001371042851508,  0.000176841611374, 0.000005074932907],\r\n",
        "\t\t[ 0.000176841611374,  0.005040677876601,  0.029076377830313, 0.046436430819499,  0.029076377830313,  0.005040677876601, 0.000176841611374],\r\n",
        "\t\t[ 0.001371042851508,  0.029076377830313,  0.058641835066605, -0.049811044772298,  0.058641835066605,  0.029076377830313, 0.001371042851508],\r\n",
        "\t\t[ 0.00265121170289 ,  0.046436430819499, -0.049811044772298, -0.497359197162173, -0.049811044772298,  0.046436430819499, 0.00265121170289 ],\r\n",
        "\t\t[ 0.001371042851508,  0.029076377830313,  0.058641835066605, -0.049811044772298,  0.058641835066605,  0.029076377830313, 0.001371042851508],\r\n",
        "\t\t[ 0.000176841611374,  0.005040677876601,  0.029076377830313, 0.046436430819499,  0.029076377830313,  0.005040677876601, 0.000176841611374],\r\n",
        "\t\t[ 0.000005074932907,  0.000176841611374,  0.001371042851508, 0.00265121170289 ,  0.001371042851508,  0.000176841611374, 0.000005074932907]]\r\n",
        "    \r\n",
        "    # Create the 3D filter.\r\n",
        "    filters = tf.transpose(tf.constant([[kernel, kernel, kernel]], dtype=tf.float32), (2, 3, 1, 0))\r\n",
        "  \r\n",
        "    # Return the filter.\r\n",
        "    return filters\r\n",
        "\r\n",
        "def laplacian_kernel_two(shape, dtype=None):\r\n",
        "    \r\n",
        "    # Set the kernel.\r\n",
        "    kernel = [\t\r\n",
        "\t\t[ 0.000001268733227,  0.000009086256607,  0.000044210402843, 0.000147589005316,  0.000342760712877,  0.000562862476099, 0.000662802925722,  0.000562862476099,  0.000342760712877, 0.000147589005316,  0.000044210402843,  0.000009086256607, 0.000001268733227],\r\n",
        "\t\t[ 0.000009086256607,  0.000062551250942,  0.000290030622363, 0.000916116269692,  0.002011423105258,  0.003159868644707, 0.003657447123561,  0.003159868644707,  0.002011423105258, 0.000916116269692,  0.000290030622363,  0.000062551250942, 0.000009086256607],\r\n",
        "\t\t[ 0.000044210402843,  0.000290030622363,  0.00126016946915, 0.003657447123561,  0.007269094457578,  0.01042709294374 , 0.011609107704875,  0.01042709294374 ,  0.007269094457578, 0.003657447123561,  0.00126016946915 ,  0.000290030622363, 0.000044210402843],\r\n",
        "\t\t[ 0.000147589005316,  0.000916116269692,  0.003657447123561, 0.009299070196277,  0.015106560194771,  0.016808486630785, 0.016246643753945,  0.016808486630785,  0.015106560194771, 0.009299070196277,  0.003657447123561,  0.000916116269692, 0.000147589005316],\r\n",
        "\t\t[ 0.000342760712877,  0.002011423105258,  0.007269094457578, 0.015106560194771,  0.014660458766651, -0.001097503065786, -0.012452761193074, -0.001097503065786,  0.014660458766651, 0.015106560194771,  0.007269094457578,  0.002011423105258, 0.000342760712877],\r\n",
        "\t\t[ 0.000562862476099,  0.003159868644707,  0.01042709294374 , 0.016808486630785, -0.001097503065786, -0.051268252318321, -0.082302736624876, -0.051268252318321, -0.001097503065786, 0.016808486630785,  0.01042709294374 ,  0.003159868644707, 0.000562862476099],\r\n",
        "\t\t[ 0.000662802925722,  0.003657447123561,  0.011609107704875, 0.016246643753945, -0.012452761193074, -0.082302736624876, -0.124339799290543, -0.082302736624876, -0.012452761193074, 0.016246643753945,  0.011609107704875,  0.003657447123561, 0.000662802925722],\r\n",
        "\t\t[ 0.000562862476099,  0.003159868644707,  0.01042709294374 , 0.016808486630785, -0.001097503065786, -0.051268252318321, -0.082302736624876, -0.051268252318321, -0.001097503065786, 0.016808486630785,  0.01042709294374 ,  0.003159868644707, 0.000562862476099],\r\n",
        "\t\t[ 0.000342760712877,  0.002011423105258,  0.007269094457578, 0.015106560194771,  0.014660458766651, -0.001097503065786, -0.012452761193074, -0.001097503065786,  0.014660458766651, 0.015106560194771,  0.007269094457578,  0.002011423105258, 0.000342760712877],\r\n",
        "\t\t[ 0.000147589005316,  0.000916116269692,  0.003657447123561, 0.009299070196277,  0.015106560194771,  0.016808486630785, 0.016246643753945,  0.016808486630785,  0.015106560194771, 0.009299070196277,  0.003657447123561,  0.000916116269692, 0.000147589005316],\r\n",
        "\t\t[ 0.000044210402843,  0.000290030622363,  0.00126016946915, 0.003657447123561,  0.007269094457578,  0.01042709294374, 0.011609107704875,  0.01042709294374 ,  0.007269094457578, 0.003657447123561,  0.00126016946915 ,  0.000290030622363, 0.000044210402843],\r\n",
        "\t\t[ 0.000009086256607,  0.000062551250942,  0.000290030622363, 0.000916116269692,  0.002011423105258,  0.003159868644707, 0.003657447123561,  0.003159868644707,  0.002011423105258, 0.000916116269692,  0.000290030622363,  0.000062551250942, 0.000009086256607],\r\n",
        "\t\t[ 0.000001268733227,  0.000009086256607,  0.000044210402843, 0.000147589005316,  0.000342760712877,  0.000562862476099, 0.000662802925722,  0.000562862476099,  0.000342760712877, 0.000147589005316,  0.000044210402843,  0.000009086256607, 0.000001268733227]\r\n",
        "\t]\r\n",
        "\t\t\r\n",
        "    # Create the 3D filter.\r\n",
        "    filters = tf.transpose(tf.constant([[kernel, kernel, kernel]], dtype=tf.float32), (2, 3, 1, 0))\r\n",
        "  \r\n",
        "    # Return the filter.\r\n",
        "    return filters\r\n",
        "    \r\n",
        "def laplacian_kernel_three(shape, dtype=None):\r\n",
        "    \r\n",
        "    # Set the kernel.\r\n",
        "    kernel =[\t\r\n",
        "\t\t[ 0.00000003276694 ,  0.000000102321053,  0.000000289823431,0.000000745118474,  0.000001740181075,  0.000003695490265,0.000007144471547,  0.000012591506332,  0.00002026037218 ,0.000029810457975,  0.000040172249113,  0.000049653076997,0.000056355461988,  0.000058779711723,  0.000056355461988,0.000049653076997,  0.000040172249113,  0.000029810457975,0.00002026037218 ,  0.000012591506332,  0.000007144471547,0.000003695490265,  0.000001740181075,  0.000000745118474,0.000000289823431,  0.000000102321053,  0.00000003276694 ],\r\n",
        "\t\t[ 0.000000102321053,  0.000000317183307,  0.000000891254046,0.000002271564152,  0.000005255987472,  0.000011052600711,0.000021151594635,  0.000036897251329,  0.000058779711723,0.000085690178219,  0.00011455564698 ,  0.000140715619025,0.000159081790068,  0.000165700731431,  0.000159081790068,0.000140715619025,  0.00011455564698 ,  0.000085690178219,0.000058779711723,  0.000036897251329,  0.000021151594635,0.000011052600711,  0.000005255987472,  0.000002271564152,0.000000891254046,  0.000000317183307,  0.000000102321053],\r\n",
        "\t\t[ 0.000000289823431,  0.000000891254046,  0.000002482179193,0.000006264686954,  0.000014340889217,  0.000029810457975,0.000056355461988,  0.000097075182089,  0.000152717393296,0.000220002752893,  0.000291045957226,  0.000354565490002,0.000398718169712,  0.000414545956269,  0.000398718169712,0.000354565490002,  0.000291045957226,  0.000220002752893,0.000152717393296,  0.000097075182089,  0.000056355461988,0.000029810457975,  0.000014340889217,  0.000006264686954, 0.000002482179193,  0.000000891254046,  0.000000289823431],\r\n",
        "\t\t[ 0.000000745118474,  0.000002271564152,  0.000006264686954,0.000015637812736,  0.00003535918443 ,  0.000072507655591,0.000135060680357,  0.000229029067423,  0.000354565490002,0.000502855776314,  0.000655890033161,  0.000789967161177,0.000881738236641,  0.00091436178089 ,  0.000881738236641,0.000789967161177,  0.000655890033161,  0.000502855776314,0.000354565490002,  0.000229029067423,  0.000135060680357,0.000072507655591,  0.00003535918443 ,  0.000015637812736, 0.000006264686954,  0.000002271564152,  0.000000745118474],\r\n",
        "\t\t[ 0.000001740181075,  0.000005255987472,  0.000014340889217,0.00003535918443 ,  0.000078831688329,  0.000159081790068,0.000291045957226,  0.000483905610509,  0.000733625931829,0.001018671159288,  0.001302594707778,  0.001543202189799,0.001703578516854,  0.00175974821168 ,  0.001703578516854,0.001543202189799,  0.001302594707778,  0.001018671159288,0.000733625931829,  0.000483905610509,  0.000291045957226,0.000159081790068,  0.000078831688329,  0.00003535918443 ,0.000014340889217,  0.000005255987472,  0.000001740181075],\r\n",
        "\t\t[ 0.000003695490265,  0.000011052600711,  0.000029810457975,0.000072507655591,  0.000159081790068,  0.000315042367288,0.000563900019106,  0.00091436178089 ,  0.001348101790401,0.001817273614395,  0.002256953506164,  0.002606773235935,0.002827478640437,  0.002902276926219,  0.002827478640437,0.002606773235935,  0.002256953506164,  0.001817273614395,0.001348101790401,  0.00091436178089 ,  0.000563900019106,0.000315042367288,  0.000159081790068,  0.000072507655591, 0.000029810457975,  0.000011052600711,  0.000003695490265],\r\n",
        "\t\t[ 0.000007144471547,  0.000021151594635,  0.000056355461988,0.000135060680357,  0.000291045957226,  0.000563900019106,0.000982804254813,  0.001543202189799,  0.002190323257653,0.002827478640437,  0.003353879875579,  0.003710770856355,0.003899844665886,  0.003956273092643,  0.003899844665886,0.003710770856355,  0.003353879875579,  0.002827478640437,0.002190323257653,  0.001543202189799,  0.000982804254813,0.000563900019106,  0.000291045957226,  0.000135060680357,0.000056355461988,  0.000021151594635,  0.000007144471547],\r\n",
        "\t\t[ 0.000012591506332,  0.000036897251329,  0.000097075182089,0.000229029067423,  0.000483905610509,  0.00091436178089 ,0.001543202189799,  0.002324767549069,  0.003128504290034,0.003776640048693,  0.004135046026703,  0.004202121657696,0.004117335028969,  0.004061660938486,  0.004117335028969,0.004202121657696,  0.004135046026703,  0.003776640048693,0.003128504290034,  0.002324767549069,  0.001543202189799,0.00091436178089 ,  0.000483905610509,  0.000229029067423, 0.000097075182089,  0.000036897251329,  0.000012591506332],\r\n",
        "\t\t[ 0.00002026037218 ,  0.000058779711723,  0.000152717393296,0.000354565490002,  0.000733625931829,  0.001348101790401,0.002190323257653,  0.003128504290034,  0.003899844665886,0.004206882475076,  0.003901217929368,  0.003138282542174,0.002354013123118,  0.002024016375783,  0.002354013123118,0.003138282542174,  0.003901217929368,  0.004206882475076,0.003899844665886,  0.003128504290034,  0.002190323257653,0.001348101790401,  0.000733625931829,  0.000354565490002,0.000152717393296,  0.000058779711723,  0.00002026037218 ],\r\n",
        "\t\t[ 0.000029810457975,  0.000085690178219,  0.000220002752893,0.000502855776314,  0.001018671159288,  0.001817273614395,0.002827478640437,  0.003776640048693,  0.004206882475076,0.003665114691663,  0.002024016375783, -0.000274375766446,-0.002303038048863, -0.003113190298269, -0.002303038048863,-0.000274375766446,  0.002024016375783,  0.003665114691663,0.004206882475076,  0.003776640048693,  0.002827478640437,0.001817273614395,  0.001018671159288,  0.000502855776314,0.000220002752893,  0.000085690178219,  0.000029810457975],\r\n",
        "\t\t[ 0.000040172249113,  0.00011455564698 ,  0.000291045957226,0.000655890033161,  0.001302594707778,  0.002256953506164,0.003353879875579,  0.004135046026703,  0.003901217929368,0.002024016375783, -0.001563031623073, -0.006017922742186,-0.009761659358786, -0.011228197398305, -0.009761659358786,-0.006017922742186, -0.001563031623073,  0.002024016375783,0.003901217929368,  0.004135046026703,  0.003353879875579,0.002256953506164,  0.001302594707778,  0.000655890033161,0.000291045957226,  0.00011455564698 ,  0.000040172249113],\r\n",
        "\t\t[ 0.000049653076997,  0.000140715619025,  0.000354565490002,0.000789967161177,  0.001543202189799,  0.002606773235935,0.003710770856355,  0.004202121657696,  0.003138282542174,-0.000274375766446, -0.006017922742186, -0.01281706307958 ,-0.018406119972447, -0.020575684156219, -0.018406119972447,-0.01281706307958 , -0.006017922742186, -0.000274375766446,0.003138282542174,  0.004202121657696,  0.003710770856355,0.002606773235935,  0.001543202189799,  0.000789967161177,0.000354565490002,  0.000140715619025,  0.000049653076997],\r\n",
        "\t\t[ 0.000056355461988,  0.000159081790068,  0.000398718169712,0.000881738236641,  0.001703578516854,  0.002827478640437,0.003899844665886,  0.004117335028969,  0.002354013123118,-0.002303038048863, -0.009761659358786, -0.018406119972447,-0.025439619702615, -0.028158102510065, -0.025439619702615,-0.018406119972447, -0.009761659358786, -0.002303038048863,0.002354013123118,  0.004117335028969,  0.003899844665886,0.002827478640437,  0.001703578516854,  0.000881738236641,0.000398718169712,  0.000159081790068,  0.000056355461988],\r\n",
        "\t\t[ 0.000058779711723,  0.000165700731431,  0.000414545956269,0.00091436178089 ,  0.00175974821168 ,  0.002902276926219,0.003956273092643,  0.004061660938486,  0.002024016375783,-0.003113190298269, -0.011228197398305, -0.020575684156219,-0.028158102510065, -0.031084949822636, -0.028158102510065,-0.020575684156219, -0.011228197398305, -0.003113190298269,0.002024016375783,  0.004061660938486,  0.003956273092643,0.002902276926219,  0.00175974821168 ,  0.00091436178089 ,0.000414545956269,  0.000165700731431,  0.000058779711723],\r\n",
        "\t\t[ 0.000056355461988,  0.000159081790068,  0.000398718169712,0.000881738236641,  0.001703578516854,  0.002827478640437,0.003899844665886,  0.004117335028969,  0.002354013123118,-0.002303038048863, -0.009761659358786, -0.018406119972447,-0.025439619702615, -0.028158102510065, -0.025439619702615,-0.018406119972447, -0.009761659358786, -0.002303038048863,0.002354013123118,  0.004117335028969,  0.003899844665886,0.002827478640437,  0.001703578516854,  0.000881738236641,0.000398718169712,  0.000159081790068,  0.000056355461988],\r\n",
        "\t\t[ 0.000049653076997,  0.000140715619025,  0.000354565490002,0.000789967161177,  0.001543202189799,  0.002606773235935,0.003710770856355,  0.004202121657696,  0.003138282542174,-0.000274375766446, -0.006017922742186, -0.01281706307958 ,-0.018406119972447, -0.020575684156219, -0.018406119972447,-0.01281706307958 , -0.006017922742186, -0.000274375766446,0.003138282542174,  0.004202121657696,  0.003710770856355,0.002606773235935,  0.001543202189799,  0.000789967161177,0.000354565490002,  0.000140715619025,  0.000049653076997],\r\n",
        "\t\t[ 0.000040172249113,  0.00011455564698 ,  0.000291045957226,0.000655890033161,  0.001302594707778,  0.002256953506164,0.003353879875579,  0.004135046026703,  0.003901217929368,0.002024016375783, -0.001563031623073, -0.006017922742186,-0.009761659358786, -0.011228197398305, -0.009761659358786,-0.006017922742186, -0.001563031623073,  0.002024016375783,0.003901217929368,  0.004135046026703,  0.003353879875579,0.002256953506164,  0.001302594707778,  0.000655890033161,0.000291045957226,  0.00011455564698 ,  0.000040172249113],\r\n",
        "\t\t[ 0.000029810457975,  0.000085690178219,  0.000220002752893,0.000502855776314,  0.001018671159288,  0.001817273614395,0.002827478640437,  0.003776640048693,  0.004206882475076,0.003665114691663,  0.002024016375783, -0.000274375766446,-0.002303038048863, -0.003113190298269, -0.002303038048863,-0.000274375766446,  0.002024016375783,  0.003665114691663,0.004206882475076,  0.003776640048693,  0.002827478640437,0.001817273614395,  0.001018671159288,  0.000502855776314,0.000220002752893,  0.000085690178219,  0.000029810457975],\r\n",
        "\t\t[ 0.00002026037218 ,  0.000058779711723,  0.000152717393296,0.000354565490002,  0.000733625931829,  0.001348101790401,0.002190323257653,  0.003128504290034,  0.003899844665886,0.004206882475076,  0.003901217929368,  0.003138282542174,0.002354013123118,  0.002024016375783,  0.002354013123118,0.003138282542174,  0.003901217929368,  0.004206882475076,0.003899844665886,  0.003128504290034,  0.002190323257653,0.001348101790401,  0.000733625931829,  0.000354565490002,0.000152717393296,  0.000058779711723,  0.00002026037218 ],\r\n",
        "\t\t[ 0.000012591506332,  0.000036897251329,  0.000097075182089,0.000229029067423,  0.000483905610509,  0.00091436178089 ,0.001543202189799,  0.002324767549069,  0.003128504290034,0.003776640048693,  0.004135046026703,  0.004202121657696,0.004117335028969,  0.004061660938486,  0.004117335028969,0.004202121657696,  0.004135046026703,  0.003776640048693,0.003128504290034,  0.002324767549069,  0.001543202189799,0.00091436178089 ,  0.000483905610509,  0.000229029067423,0.000097075182089,  0.000036897251329,  0.000012591506332],\r\n",
        "\t\t[ 0.000007144471547,  0.000021151594635,  0.000056355461988,0.000135060680357,  0.000291045957226,  0.000563900019106,0.000982804254813,  0.001543202189799,  0.002190323257653,0.002827478640437,  0.003353879875579,  0.003710770856355,0.003899844665886,  0.003956273092643,  0.003899844665886,0.003710770856355,  0.003353879875579,  0.002827478640437,0.002190323257653,  0.001543202189799,  0.000982804254813,0.000563900019106,  0.000291045957226,  0.000135060680357,0.000056355461988,  0.000021151594635,  0.000007144471547],\r\n",
        "\t\t[ 0.000003695490265,  0.000011052600711,  0.000029810457975,0.000072507655591,  0.000159081790068,  0.000315042367288,0.000563900019106,  0.00091436178089 ,  0.001348101790401,0.001817273614395,  0.002256953506164,  0.002606773235935,0.002827478640437,  0.002902276926219,  0.002827478640437,0.002606773235935,  0.002256953506164,  0.001817273614395,0.001348101790401,  0.00091436178089 ,  0.000563900019106,0.000315042367288,  0.000159081790068,  0.000072507655591,0.000029810457975,  0.000011052600711,  0.000003695490265],\r\n",
        "\t\t[ 0.000001740181075,  0.000005255987472,  0.000014340889217,0.00003535918443 ,  0.000078831688329,  0.000159081790068,0.000291045957226,  0.000483905610509,  0.000733625931829,0.001018671159288,  0.001302594707778,  0.001543202189799,0.001703578516854,  0.00175974821168 ,  0.001703578516854,0.001543202189799,  0.001302594707778,  0.001018671159288,0.000733625931829,  0.000483905610509,  0.000291045957226,0.000159081790068,  0.000078831688329,  0.00003535918443 ,0.000014340889217,  0.000005255987472,  0.000001740181075],\r\n",
        "\t\t[ 0.000000745118474,  0.000002271564152,  0.000006264686954,0.000015637812736,  0.00003535918443 ,  0.000072507655591,0.000135060680357,  0.000229029067423,  0.000354565490002,0.000502855776314,  0.000655890033161,  0.000789967161177,0.000881738236641,  0.00091436178089 ,  0.000881738236641,0.000789967161177,  0.000655890033161,  0.000502855776314,0.000354565490002,  0.000229029067423,  0.000135060680357,0.000072507655591,  0.00003535918443 ,  0.000015637812736,0.000006264686954,  0.000002271564152,  0.000000745118474],\r\n",
        "\t\t[ 0.000000289823431,  0.000000891254046,  0.000002482179193,0.000006264686954,  0.000014340889217,  0.000029810457975,0.000056355461988,  0.000097075182089,  0.000152717393296,0.000220002752893,  0.000291045957226,  0.000354565490002,0.000398718169712,  0.000414545956269,  0.000398718169712,0.000354565490002,  0.000291045957226,  0.000220002752893,0.000152717393296,  0.000097075182089,  0.000056355461988,0.000029810457975,  0.000014340889217,  0.000006264686954,0.000002482179193,  0.000000891254046,  0.000000289823431],\r\n",
        "\t\t[ 0.000000102321053,  0.000000317183307,  0.000000891254046,0.000002271564152,  0.000005255987472,  0.000011052600711,0.000021151594635,  0.000036897251329,  0.000058779711723,0.000085690178219,  0.00011455564698 ,  0.000140715619025,0.000159081790068,  0.000165700731431,  0.000159081790068,0.000140715619025,  0.00011455564698 ,  0.000085690178219,0.000058779711723,  0.000036897251329,  0.000021151594635,0.000011052600711,  0.000005255987472,  0.000002271564152,0.000000891254046,  0.000000317183307,  0.000000102321053],\r\n",
        "\t\t[ 0.00000003276694 ,  0.000000102321053,  0.000000289823431,0.000000745118474,  0.000001740181075,  0.000003695490265,0.000007144471547,  0.000012591506332,  0.00002026037218 ,0.000029810457975,  0.000040172249113,  0.000049653076997,0.000056355461988,  0.000058779711723,  0.000056355461988,0.000049653076997,  0.000040172249113,  0.000029810457975,0.00002026037218 ,  0.000012591506332,  0.000007144471547,0.000003695490265,  0.000001740181075,  0.000000745118474,0.000000289823431,  0.000000102321053,  0.00000003276694 ]]\r\n",
        "    \r\n",
        "    # Return the filter.\r\n",
        "    filters = tf.transpose(tf.constant([[kernel, kernel, kernel]], dtype=tf.float32), (2, 3, 1, 0))\r\n",
        "  \r\n",
        "    return filters\r\n",
        "\r\n",
        "def sobel_kernel_one(shape, dtype=None):\r\n",
        "    \r\n",
        "    # Set the kernel.\r\n",
        "    kernel = [\r\n",
        "              [ 1,0,-1],\r\n",
        "\t\t          [ 2,0,-2],\r\n",
        "\t\t          [ 1,0,-1]\r\n",
        "            ]\r\n",
        "    \r\n",
        "    # Create the 3D filter.\r\n",
        "    filters = tf.transpose(tf.constant([[kernel, kernel, kernel]], dtype=tf.float32), (2, 3, 1, 0))\r\n",
        "  \r\n",
        "    # Return the filter.\r\n",
        "    return filters\r\n",
        "\r\n",
        "def sobel_kernel_two(shape, dtype=None):\r\n",
        "    \r\n",
        "    # Set the kernel.\r\n",
        "    kernel = [\t\r\n",
        "\t\t[1,2,1],\r\n",
        "\t\t[ 0,0,0],\r\n",
        "\t\t[ -1,-2,-1]\r\n",
        "\t  ]\r\n",
        "\t\t\r\n",
        "    # Create the 3D filter.\r\n",
        "    filters = tf.transpose(tf.constant([[kernel, kernel, kernel]], dtype=tf.float32), (2, 3, 1, 0))\r\n",
        "  \r\n",
        "    # Return the filter.\r\n",
        "    return filters\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW4ZIPo6oORY"
      },
      "source": [
        "# Method that creates a model for the different kernels depending on the parameters.\r\n",
        "def createModel(kernelSize, kernelInitializer, saveName, kernelTestImages):\r\n",
        "    # Set the batchize\r\n",
        "    batchSize = 100\r\n",
        "    \r\n",
        "    # Set the layer. \r\n",
        "    layer1 =  keras.layers.Conv2D(1, kernel_size=kernelSize, kernel_initializer=kernelInitializer, padding='same', name=\"oneLayer\")(input_img)\r\n",
        "    createdModel = Model(input_img, layer1)\r\n",
        "    createdModel.get_layer(\"oneLayer\").trainable = False\r\n",
        "\r\n",
        "    # Compile and give a summary of the model\r\n",
        "    createdModel.compile(optimizer='adam',loss=mean_squared_error, metrics=['accuracy'])\r\n",
        "    createdModel.summary()\r\n",
        "\r\n",
        "    # Save the model, and save it.\r\n",
        "    createdModel.fit(kernelTestImages, kernelTestImages, epochs =1, batch_size =batchSize, validation_data=(kernelTestImages, kernelTestImages))\r\n",
        "    createdModel.save(saveName)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDkL_N0Hmkdg"
      },
      "source": [
        "# Method that creates a model for the filters depending on if it is sobel or not.\r\n",
        "def createModels(sobel, kernelTestImages):\r\n",
        "\r\n",
        "  # If sobel arrays.\r\n",
        "  if sobel:\r\n",
        "    # Create the two kernels. \r\n",
        "    sobel = createModel((3, 3),sobel_kernel_one,\"/content/drive/MyDrive/Models/sobel1_OneImage\", kernelTestImages)\r\n",
        "    sobel = createModel((3, 3),sobel_kernel_two,\"/content/drive/MyDrive/Models/sobel2_OneImage\", kernelTestImages)    \r\n",
        "  else: # Else create laplacian\r\n",
        "    laplacian = createModel((7,7),laplacian_kernel_one,\"/content/drive/MyDrive/Models/laplacian1_OneImage\", kernelTestImages)\r\n",
        "    laplacian = createModel((13,13),laplacian_kernel_two,\"/content/drive/MyDrive/Models/laplacian2_OneImage\", kernelTestImages)\r\n",
        "    laplacian = createModel((27,27),laplacian_kernel_three,\"/content/drive/MyDrive/Models/laplacian3_OneImage\", kernelTestImages)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip5dLVsPnHAh"
      },
      "source": [
        "# Method that loads models. Sobel parameter indicator if it is sobel or laplacian\r\n",
        "def loadModels(sobel):\r\n",
        "\r\n",
        "  # Array to hold the models.\r\n",
        "  modelArray = []\r\n",
        "\r\n",
        "  # If sobel, load the sobel arrays, else load laplacianmodels.\r\n",
        "  if sobel:\r\n",
        "    modelArray.append(load_model(\"/content/drive/MyDrive/Models/sobel1_OneImage\"))\r\n",
        "    modelArray.append(load_model(\"/content/drive/MyDrive/Models/sobel2_OneImage\"))\r\n",
        "  else:\r\n",
        "    modelArray.append(load_model(\"/content/drive/MyDrive/Models/laplacian1_OneImage\"))\r\n",
        "    modelArray.append(load_model(\"/content/drive/MyDrive/Models/laplacian2_OneImage\"))\r\n",
        "    modelArray.append(load_model(\"/content/drive/MyDrive/Models/laplacian3_OneImage\"))\r\n",
        "\r\n",
        "  return modelArray"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVzYBvJHz8-y"
      },
      "source": [
        "# Method that creates the nuumpy arrays based on where to save it and which models need to be done.\r\n",
        "def createSaveNumpyArrays(locationList, all_imagesNames, main_path, models):\r\n",
        "\r\n",
        "  # Create the directories if they don't exist.\r\n",
        "  for location in locationList:\r\n",
        "    if not os.path.exists(location):\r\n",
        "      os.makedirs(location)\r\n",
        "\r\n",
        "  # Get the laplacian images\r\n",
        "  for index in  tq.tqdm(range(len(all_imagesNames))):\r\n",
        "\r\n",
        "    # Get the image name. \r\n",
        "    imageName = all_imagesNames[index].split('.')[0]\r\n",
        "\r\n",
        "    # Get an image and reshape it so it can be used. \r\n",
        "    image = getImage(main_path,index,all_imagesNames)\r\n",
        "\r\n",
        "    # Reform the acutal image to work on.\r\n",
        "    actualImage = np.reshape([image], (1, img_sizeY, img_sizeX, 3))\r\n",
        "\r\n",
        "    # Loop over the different models. \r\n",
        "    for x in range(len(models)):\r\n",
        "      \r\n",
        "      # Get the prediction of the image.\r\n",
        "      modelledImage = models[x].predict(actualImage)\r\n",
        "\r\n",
        "      # Save the image. \r\n",
        "      np.save(locationList[x] +'/{}'.format(imageName), modelledImage[0])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tfPo9rwWLF"
      },
      "source": [
        "# Method that gets the paper sized auto encoder and adds sobel or laplacian layers if need be\r\n",
        "def getPaper(sobel, laplacian):\r\n",
        "\r\n",
        "  # Encoder\r\n",
        "  conv1 =  keras.layers.Conv2D(32, (3, 3), activation='relu',padding='same')(input_img) # layer 2\r\n",
        "\r\n",
        "  # Layer 3\r\n",
        "  pool1 = keras.layers.MaxPool2D(pool_size=(2, 2))(conv1) \r\n",
        "  conv2 = keras.layers.Conv2D(16, (3, 3), activation='relu',padding='same')(pool1)\r\n",
        "\r\n",
        "  #decoder \r\n",
        "\r\n",
        "  #layer 4\r\n",
        "  up1 = keras.layers.UpSampling2D((2,2))(conv2)\r\n",
        "  conv3 = keras.layers.Conv2D(32, (3, 3), activation='relu',padding='same')(up1)\r\n",
        "  #layer 5\r\n",
        "  decoded = keras.layers.Conv2D(3, (3, 3), activation='tanh',padding='same', name = \"decoded\")(conv3)\r\n",
        "\r\n",
        "  if sobel:\r\n",
        "    # The sobel branching layers. \r\n",
        "    sobel1Actual =  keras.layers.Conv2D(1, kernel_size=(3, 3), kernel_initializer=sobel_kernel_one, padding='same', name=\"sobel1\")(decoded)\r\n",
        "    sobel2Actual =  keras.layers.Conv2D(1, kernel_size=(3, 3), kernel_initializer=sobel_kernel_two, padding='same', name=\"sobel2\")(decoded)\r\n",
        "\r\n",
        "    # Define the different outputs.\r\n",
        "    autoencoder = Model(input_img, outputs = [decoded,sobel1Actual,sobel2Actual])\r\n",
        "\r\n",
        "    # Set the layers to not train. \r\n",
        "    autoencoder.get_layer(\"sobel1\").trainable = False\r\n",
        "    autoencoder.get_layer(\"sobel2\").trainable = False\r\n",
        "\r\n",
        "    # Set the weights array. \r\n",
        "    lossWeight = [1/2.0,1/4.0,1/4.0]\r\n",
        "\r\n",
        "    # Compile\r\n",
        "    autoencoder.compile(optimizer='adam',loss=[mean_squared_error, mean_squared_error, mean_squared_error], metrics=['accuracy'],loss_weights=lossWeight)\r\n",
        "    autoencoder.summary()\r\n",
        "\r\n",
        "    # Return the auto encoder.\r\n",
        "    return autoencoder\r\n",
        "\r\n",
        "  elif laplacian:\r\n",
        "    # The laplacian branching layers. \r\n",
        "    laplacian1Actual =  keras.layers.Conv2D(1, kernel_size=(7, 7), kernel_initializer=laplacian_kernel_one, padding='same', name=\"laplacian1\")(decoded)\r\n",
        "    laplacian2Actual =  keras.layers.Conv2D(1, kernel_size=(13, 13), kernel_initializer=laplacian_kernel_two, padding='same', name=\"laplacian2\")(decoded)\r\n",
        "    laplacian3Actual =  keras.layers.Conv2D(1, kernel_size=(27, 27), kernel_initializer=laplacian_kernel_three, padding='same', name=\"laplacian3\")(decoded)\r\n",
        "\r\n",
        "    # Define the different outputs.\r\n",
        "    autoencoder = Model(input_img, outputs = [decoded,laplacian1Actual,laplacian2Actual,laplacian3Actual])\r\n",
        "\r\n",
        "    # Set the layers to not train. \r\n",
        "    autoencoder.get_layer(\"laplacian1\").trainable = False\r\n",
        "    autoencoder.get_layer(\"laplacian2\").trainable = False\r\n",
        "    autoencoder.get_layer(\"laplacian3\").trainable = False\r\n",
        "\r\n",
        "    # Set the weights array. \r\n",
        "    lossWeight = [1/2.0,1/6.0,1/6.0,1/6.0]\r\n",
        "\r\n",
        "    # Compile\r\n",
        "    autoencoder.compile(optimizer='adam',loss=[mean_squared_error, mean_squared_error,mean_squared_error,mean_squared_error], metrics=['accuracy'],loss_weights=lossWeight)\r\n",
        "    autoencoder.summary()\r\n",
        "\r\n",
        "    # Return the auto encoder.\r\n",
        "    return autoencoder\r\n",
        "\r\n",
        "  else: # Normal auto encoder\r\n",
        "    # Set the values for one it has no filters. \r\n",
        "    autoencoder = Model(input_img, outputs = decoded)\r\n",
        "\r\n",
        "    # Compile\r\n",
        "    autoencoder.compile(optimizer='adam',loss=mean_squared_error, metrics=['accuracy'])\r\n",
        "    autoencoder.summary()\r\n",
        "\r\n",
        "    # Return the auto encoder.\r\n",
        "    return autoencoder\r\n",
        "\r\n",
        "# Method that gets the deeper auto encoder and adds the laplacian or sobel layer if needed. \r\n",
        "def getDeep(sobel, laplacian):\r\n",
        "\r\n",
        "  # THe layers of the algorithm, these ones are for the paper.\r\n",
        "  conv1 =  keras.layers.Conv2D(32, (3, 3), activation='relu',padding='same')(input_img) # layer 2\r\n",
        "  pool1 = keras.layers.MaxPool2D(pool_size=(2, 2), padding= 'same')(conv1) # next two lines are layer 3\r\n",
        "  conv2 = keras.layers.Conv2D(16, (3, 3), activation='relu',padding='same')(pool1)\r\n",
        "\r\n",
        "  pool2 = keras.layers.MaxPool2D(pool_size=(2, 2),padding= \"same\")(conv2) # next two lines are an extra layer\r\n",
        "  conv3 = keras.layers.Conv2D(8, (3, 3), activation='relu',padding='same')(pool2)\r\n",
        "\r\n",
        "  pool3 = keras.layers.MaxPool2D(pool_size=(2, 2),padding= \"same\")(conv3) # next two lines are another extra layer\r\n",
        "  conv4 = keras.layers.Conv2D(4, (3, 3), activation='relu',padding='same')(pool3)\r\n",
        "\r\n",
        "  pool4 = keras.layers.MaxPool2D(pool_size=(2, 2),padding= \"same\")(conv4) # next two lines are another extra layer\r\n",
        "  conv5 = keras.layers.Conv2D(2, (3, 3), activation='relu',padding='same')(pool4)\r\n",
        "\r\n",
        "  #decoder \r\n",
        "\r\n",
        "  # Extra layer to combat one above\r\n",
        "  up1 = keras.layers.UpSampling2D((2,2))(conv5)\r\n",
        "  conv6 = keras.layers.Conv2D(4, (3, 3), activation='relu',padding='same')(up1)\r\n",
        "\r\n",
        "  # Crop to get the correct size.\r\n",
        "  cropped = Cropping2D(cropping=((1, 0), (1, 0)), data_format=None)(conv6)\r\n",
        "\r\n",
        "\r\n",
        "  # Extra layer to combat one above\r\n",
        "  up2 = keras.layers.UpSampling2D((2,2))(cropped)\r\n",
        "  conv7 = keras.layers.Conv2D(8, (3, 3), activation='relu',padding='same')(up2)\r\n",
        "\r\n",
        "  # Crop to get the correct size.\r\n",
        "  cropped = Cropping2D(cropping=((0, 0), (1, 0)), data_format=None)(conv7) \r\n",
        "\r\n",
        "  # Extra layer to combat one above\r\n",
        "  up3 = keras.layers.UpSampling2D((2,2))(cropped)\r\n",
        "  conv8 = keras.layers.Conv2D(16, (3, 3), activation='relu',padding='same')(up3)\r\n",
        "\r\n",
        "  #layer 4\r\n",
        "  up4 = keras.layers.UpSampling2D((2,2))(conv8)\r\n",
        "  conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu',padding='same')(up4)\r\n",
        "  #layer 5\r\n",
        "  decoded = keras.layers.Conv2D(3, (3, 3), activation='tanh',padding='same', name = \"decoded\")(conv9)\r\n",
        "\r\n",
        "  if sobel:\r\n",
        "    # The sobel branching layers. \r\n",
        "    sobel1Actual =  keras.layers.Conv2D(1, kernel_size=(3, 3), kernel_initializer=sobel_kernel_one, padding='same', name=\"sobel1\")(decoded)\r\n",
        "    sobel2Actual =  keras.layers.Conv2D(1, kernel_size=(3, 3), kernel_initializer=sobel_kernel_two, padding='same', name=\"sobel2\")(decoded)\r\n",
        "\r\n",
        "    # Define the different outputs.\r\n",
        "    autoencoder = Model(input_img, outputs = [decoded,sobel1Actual,sobel2Actual])\r\n",
        "\r\n",
        "    # Set the layers to not train. \r\n",
        "    autoencoder.get_layer(\"sobel1\").trainable = False\r\n",
        "    autoencoder.get_layer(\"sobel2\").trainable = False\r\n",
        "\r\n",
        "    # Set the weights array. \r\n",
        "    lossWeight = [1/2.0,1/4.0,1/4.0]\r\n",
        "\r\n",
        "    # Compile\r\n",
        "    autoencoder.compile(optimizer='adam',loss=[mean_squared_error, mean_squared_error, mean_squared_error], metrics=['accuracy'],loss_weights=lossWeight)\r\n",
        "    autoencoder.summary()\r\n",
        "\r\n",
        "    # Return the auto encoder.\r\n",
        "    return autoencoder\r\n",
        "\r\n",
        "  elif laplacian:\r\n",
        "    # The laplacian branching layers. \r\n",
        "    laplacian1Actual =  keras.layers.Conv2D(1, kernel_size=(7, 7), kernel_initializer=laplacian_kernel_one, padding='same', name=\"laplacian1\")(decoded)\r\n",
        "    laplacian2Actual =  keras.layers.Conv2D(1, kernel_size=(13, 13), kernel_initializer=laplacian_kernel_two, padding='same', name=\"laplacian2\")(decoded)\r\n",
        "    laplacian3Actual =  keras.layers.Conv2D(1, kernel_size=(27, 27), kernel_initializer=laplacian_kernel_three, padding='same', name=\"laplacian3\")(decoded)\r\n",
        "\r\n",
        "    # Define the different outputs.\r\n",
        "    autoencoder = Model(input_img, outputs = [decoded,laplacian1Actual,laplacian2Actual,laplacian3Actual])\r\n",
        "\r\n",
        "    # Set the layers to not train. \r\n",
        "    autoencoder.get_layer(\"laplacian1\").trainable = False\r\n",
        "    autoencoder.get_layer(\"laplacian2\").trainable = False\r\n",
        "    autoencoder.get_layer(\"laplacian3\").trainable = False\r\n",
        "\r\n",
        "    # Set the weights array. \r\n",
        "    lossWeight = [1/2.0,1/6.0,1/6.0,1/6.0]\r\n",
        "\r\n",
        "    # Compile.\r\n",
        "    autoencoder.compile(optimizer='adam',loss=[mean_squared_error, mean_squared_error,mean_squared_error,mean_squared_error], metrics=['accuracy'],loss_weights=lossWeight)\r\n",
        "    autoencoder.summary()\r\n",
        "\r\n",
        "    # Return the auto encoder.\r\n",
        "    return autoencoder\r\n",
        "\r\n",
        "  else:\r\n",
        "    # Set the values for one it has no filters. \r\n",
        "    autoencoder = Model(input_img, outputs = decoded)\r\n",
        "\r\n",
        "    # Compile.\r\n",
        "    autoencoder.compile(optimizer='adam',loss=mean_squared_error, metrics=['accuracy'])\r\n",
        "    autoencoder.summary()\r\n",
        "\r\n",
        "    # Return the auto encoder.\r\n",
        "    return autoencoder"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MILqNcIu4bTn"
      },
      "source": [
        "# Method that gets the images for the training. \r\n",
        "def image_generator(bs, startPos, endPos, sobel, laplacian, locationList, imageNameList ):\r\n",
        "    # Set the index\r\n",
        "    index = startPos\r\n",
        "\r\n",
        "    while True:\r\n",
        "        # Initialize our image batches.\r\n",
        "        startImages = []\r\n",
        "        imageLibrary = {}\r\n",
        "        for x in range(len(locationList)):\r\n",
        "          imageLibrary[x] = []\r\n",
        "        # keep looping until we reach our batch size\r\n",
        "        while (len(startImages) < bs):\r\n",
        "            if(index == endPos):\r\n",
        "                index = startPos\r\n",
        "\r\n",
        "            # Get the images and numpy array.s \r\n",
        "            startImages.append(np.array(getImage(main_path, index,imageNameList)))\r\n",
        "            for x in range(len(locationList)):\r\n",
        "              imageLibrary[x].append((getNpy(locationList[x], index, imageNameList)))\r\n",
        "\r\n",
        "            # Increment the index. \r\n",
        "            index +=1\r\n",
        "\r\n",
        "        # Reshape the arrays\r\n",
        "        startImages = np.reshape(startImages, (len(startImages), img_sizeY, img_sizeX, 3))\r\n",
        "        \r\n",
        "        for x in range(len(locationList)):\r\n",
        "          imageLibrary[x] = np.reshape(imageLibrary[x], (len(imageLibrary[x]), img_sizeY, img_sizeX, 1)) \r\n",
        "\r\n",
        "        # Yield the images. \r\n",
        "        if laplacian:\r\n",
        "          yield startImages, { \"decoded\" : startImages, \"laplacian1\" : imageLibrary[0], \"laplacian2\" : imageLibrary[1], \"laplacian3\" :imageLibrary[2]}\r\n",
        "        elif sobel:\r\n",
        "          # Yield the images. \r\n",
        "          yield startImages, { \"decoded\" : startImages, \"sobel1\" : imageLibrary[0], \"sobel2\" : imageLibrary[1]}\r\n",
        "        else:\r\n",
        "          yield startImages, { \"decoded\" : startImages} "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPeXP_l3TDDd"
      },
      "source": [
        "# Method that returns teh callback.\r\n",
        "def getCallbacks(filepath):\r\n",
        "\r\n",
        "  # Create the callback function\r\n",
        "  checkpoint_filepath = filepath + \"-{epoch:03d}.h5\"\r\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "      filepath=checkpoint_filepath,\r\n",
        "      save_weights_only=False,\r\n",
        "      monitor='loss',\r\n",
        "      verbose = 1,\r\n",
        "      mode='min',\r\n",
        "      save_best_only = True,\r\n",
        "      epochs = 10\r\n",
        "    )\r\n",
        "\r\n",
        "  # Return the callbacks. \r\n",
        "  return [model_checkpoint_callback]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7_zK_Hhz2fa"
      },
      "source": [
        "# Method that saves losses based on the fitted results, name of model, epochs ran and if there is a filter used or not.\r\n",
        "def saveLosses(fitted, modelName, epochCount, filter):\r\n",
        "\r\n",
        "  # Set the save location names. \r\n",
        "  lossHistoryName = \"/content/drive/MyDrive/Loss/\" + modelName + \"lossHistoryEpoch\" + str(epochCount) + \".txt\"\r\n",
        "  vallHistoryName = \"/content/drive/MyDrive/Loss/\" + modelName + \"vall_lossHistoryEpoch\" + str(epochCount) + \".txt\"\r\n",
        "  decodedHistoryName = \"/content/drive/MyDrive/Loss/\" + modelName + \"decoded_lossHistoryEpoch\" + str(epochCount) + \".txt\"\r\n",
        "\r\n",
        "  # Get the numpy loss information.\r\n",
        "  loss_history = fitted.history[\"loss\"]\r\n",
        "  numpy_loss_history = np.array(loss_history)\r\n",
        "  np.savetxt(lossHistoryName, numpy_loss_history, delimiter=\",\")\r\n",
        "  files.download(lossHistoryName)\r\n",
        "\r\n",
        "  # Get the numpy vallloss information.\r\n",
        "  loss_history = fitted.history[\"val_loss\"]\r\n",
        "  numpy_loss_history = np.array(loss_history)\r\n",
        "  np.savetxt(vallHistoryName, numpy_loss_history, delimiter=\",\")\r\n",
        "  files.download(vallHistoryName)\r\n",
        "\r\n",
        "  # If there are no filters, we are done now.\r\n",
        "  if not filter:\r\n",
        "    return\r\n",
        "\r\n",
        "  # Get the numpy loss information.\r\n",
        "  loss_history = fitted.history[\"decoded_loss\"]\r\n",
        "  numpy_loss_history = np.array(loss_history)\r\n",
        "  np.savetxt(decodedHistoryName, numpy_loss_history, delimiter=\",\")\r\n",
        "  files.download(decodedHistoryName)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PHC37Nm1hRO"
      },
      "source": [
        "# Method that does predictions on all the images and saves them\r\n",
        "def getPrediction(autoEncoder,main_path, all_imagesNames, filters ):\r\n",
        "  # Make the folder if it doesn't exist. \r\n",
        "  if not os.path.exists('Predicted/'):\r\n",
        "      os.makedirs('Predicted/')\r\n",
        "\r\n",
        "  # Loop over the incdices.\r\n",
        "  for index in tq.tqdm(range(len(all_imagesNames))):\r\n",
        "\r\n",
        "      # Get an immage.\r\n",
        "      image = getImage(main_path, index, all_imagesNames)\r\n",
        "\r\n",
        "      # Create a list to work on.\r\n",
        "      predictImage = [(np.array(image))]\r\n",
        "\r\n",
        "      # Make it a workable numpy array.\r\n",
        "      predictImage = np.reshape(predictImage, (len(predictImage), img_sizeY, img_sizeX, 3))\r\n",
        "\r\n",
        "      # Get the all the images it creates. \r\n",
        "      returnedImageList =  autoEncoder.predict(predictImage)\r\n",
        "\r\n",
        "      # Get the image name.\r\n",
        "      imageName = all_imagesNames[index].split('.')[0]\r\n",
        "\r\n",
        "      # Set teh variable. \r\n",
        "      returnedImage = None\r\n",
        "\r\n",
        "      # If filters are used we need to grab the image differently.\r\n",
        "      if filters:\r\n",
        "        # Save the actual first image in the list, grab the first one in the \"list\" and then the decoded one.\r\n",
        "        returnedImage = returnedImageList[0][0]\r\n",
        "      else:\r\n",
        "        returnedImage = returnedImageList[0]\r\n",
        "\r\n",
        "      # Clip the image values. \r\n",
        "      returnedImage = np.clip(returnedImage,0,1)\r\n",
        "      \r\n",
        "      # Save the image. \r\n",
        "      matplotlib.image.imsave(\"Predicted/{}.png\".format(imageName), returnedImage)\r\n",
        "   \r\n",
        "    "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQNmyQDM2nwN"
      },
      "source": [
        "# Method that displays the decoded image, and the original\r\n",
        "def displayImage(decoded_imgs, kernelTestImage, sobel, laplacian):\r\n",
        "  n = 1\r\n",
        "\r\n",
        "  # Display the original.\r\n",
        "  plt.figure(figsize=(30,30 ))\r\n",
        "  for i in range(0, n ):\r\n",
        "      # Display original\r\n",
        "      ax = plt.subplot(5, 1, 1)\r\n",
        "      plt.imshow(kernelTestImage[i])\r\n",
        "      plt.gray()\r\n",
        "      ax.get_xaxis().set_visible(False)\r\n",
        "      ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "  # If no filters used load it differently.\r\n",
        "  if not sobel and not laplacian:\r\n",
        "    # Display reconstruction\r\n",
        "      ax = plt.subplot(5, 1, 1 + n)\r\n",
        "      plt.imshow(decoded_imgs[0])\r\n",
        "      plt.gray()\r\n",
        "      ax.get_xaxis().set_visible(False)\r\n",
        "      ax.get_yaxis().set_visible(False)\r\n",
        "    \r\n",
        "\r\n",
        "  # If either filter, load the imaes predicted from the filter models. \r\n",
        "  if sobel or laplacian:\r\n",
        "\r\n",
        "      # Display reconstruction\r\n",
        "    ax = plt.subplot(5, 1, 1 + n)\r\n",
        "    plt.imshow(decoded_imgs[0][i])\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "      # Display reconstruction\r\n",
        "    ax = plt.subplot(5, 1, 1 + n * 2)\r\n",
        "    plt.imshow(decoded_imgs[1][i].squeeze(axis=2))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "        # Display reconstruction\r\n",
        "    ax = plt.subplot(5, 1, 1 + n * 3)\r\n",
        "    plt.imshow(decoded_imgs[2][i].squeeze(axis=2))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "  if laplacian:\r\n",
        "    # Display reconstruction\r\n",
        "    ax = plt.subplot(5, 1, 1 + n * 4)\r\n",
        "    plt.imshow(decoded_imgs[3][i].squeeze(axis=2))\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "      \r\n",
        "  plt.show()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqOxpwMm_Lxj"
      },
      "source": [
        "# Get all the image names.\r\n",
        "imageNames = loadAllImageNames()\r\n",
        "\r\n",
        "# Get a test image.\r\n",
        "testImage = getTestImage(imageNames)\r\n",
        "\r\n",
        "# List for the different models.\r\n",
        "models = []\r\n",
        "\r\n",
        "# List to save the paths. \r\n",
        "locationList = []\r\n",
        "\r\n",
        "# Add the needed paths.\r\n",
        "if sobel:\r\n",
        "  locationList.append(sobel_one_path)\r\n",
        "  locationList.append(sobel_two_path)\r\n",
        "elif laplacian:\r\n",
        "  locationList.append(laplacian_one_path)\r\n",
        "  locationList.append(laplacian_two_path)\r\n",
        "  locationList.append(laplacian_three_path)\r\n",
        "\r\n",
        "# If a filter is used, handle it.\r\n",
        "if any([sobel,laplacian]):\r\n",
        "\r\n",
        "  createModels(sobel, testImage)\r\n",
        "  models = loadModels(sobel)\r\n",
        "\r\n",
        "  # Create the numpy arrays. \r\n",
        "  print(\"Create the needed numpy array\")\r\n",
        "  createSaveNumpyArrays(locationList, imageNames, main_path, models)\r\n",
        "\r\n",
        "# Set teh empty auto encoder.\r\n",
        "autoEncoder = None\r\n",
        "\r\n",
        "# Create the models as needed.\r\n",
        "if deep:\r\n",
        "  autoEncoder = getDeep(sobel, laplacian)\r\n",
        "else:\r\n",
        "  autoEncoder = getPaper(sobel, laplacian)\r\n",
        "\r\n",
        "# Create the generators\r\n",
        "trainGen = image_generator(BS,0,4500, sobel, laplacian, locationList,imageNames)\r\n",
        "testGen = image_generator(BS, 4500,len(imageNames),sobel, laplacian, locationList,imageNames)\r\n",
        "\r\n",
        "# Set the callback list.\r\n",
        "callbackList = getCallbacks(\"/content/drive/MyDrive/Checkpoints/weights-improvements-{}-epoch{}\".format(autoEncoderName,baseEpochs))\r\n",
        "\r\n",
        "# Load auto encoder if need be.\r\n",
        "if loadNameFitting is not None:\r\n",
        "  autoEncoder = load_model(loadNameFitting)\r\n",
        "\r\n",
        "trainImageCount = 4500\r\n",
        "validationCount = len(imageNames) -4500\r\n",
        "\r\n",
        "# Fit the algorithm. \r\n",
        "fitted = autoEncoder.fit(x = trainGen, steps_per_epoch= trainImageCount // BS, validation_data= testGen, validation_steps= validationCount // BS, epochs= EPOCHS, verbose = 1,callbacks = callbackList)\r\n",
        "\r\n",
        "# Save the auto encoder. \r\n",
        "autoEncoder.save(\"/content/drive/MyDrive/ModelsRun2/{}_epoch{}\".format(autoEncoderName,baseEpochs + EPOCHS))\r\n",
        "\r\n",
        "# Run the actual model to test if it runs properly. \r\n",
        "decoded_img = autoEncoder.predict(testImage)\r\n",
        "displayImage(decoded_img,testImage, sobel, laplacian)\r\n",
        "\r\n",
        "# Save the losses.\r\n",
        "saveLosses(fitted, autoEncoderName, baseEpochs + EPOCHS, any([sobel,laplacian]))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JToU4g1sCNao"
      },
      "source": [
        "# Load the auto encoder and do the predictions. \r\n",
        "autoEncoder = load_model(loadNamePrediction)\r\n",
        "getPrediction(autoEncoder, main_path,imageNames, any([sobel,laplacian]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSoyg-WNWkMr"
      },
      "source": [
        "!zip -r deepWithoutFiltersEpoch100.zip /content/Predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSpfBSscdmbh"
      },
      "source": [
        "!cp /content/deepWithoutFiltersEpoch100.zip /content/drive/MyDrive/GeneratedImagesEpoch100/deepWithoutFiltersFacesEpoch100.zip"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}